{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying CRISP-DM on the MIMIC-3 Dataset (Part II)\n",
    "In this notebook, I apply the 3 last phases of the CRISP-DM process:\n",
    "\n",
    "4. Modeling\n",
    "5. Evaluation\n",
    "6. Deployment\n",
    "\n",
    "<img src=\"./media/crisp.png\" width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note here is that we prepare the data for training the model (it would be still related to the step 3). However, the main part of this notebook is related to the final 3 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import awswrangler as wr\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The small part related to step 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'mimiciii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "with ce as\n",
    "(\n",
    "  select\n",
    "    icustay_id, charttime, itemid, valuenum\n",
    "  from chartevents\n",
    "  -- specify what data we want from chartevents\n",
    "  where itemid in\n",
    "  (\n",
    "  211, -- Heart Rate\n",
    "  618, --\tRespiratory Rate\n",
    "  615 --\tResp Rate (Total)\n",
    "  )\n",
    "  -- how did we know heart rates were stored using ITEMID 211? Simple, we looked in D_ITEMS!\n",
    "  -- Try it for yourself: select * from d_items where lower(label) like '%heart rate%'\n",
    ")\n",
    "select\n",
    "  -- ICUSTAY_ID identifies each unique patient ICU stay\n",
    "  -- note that if the same person stays in the ICU more than once, each stay would have a *different* ICUSTAY_ID\n",
    "  -- however, since it's the same person, all those stays would have the same SUBJECT_ID\n",
    "  ie.icustay_id\n",
    "\n",
    "  -- this is the outcome of interest: in-hospital mortality\n",
    "  , max(adm.HOSPITAL_EXPIRE_FLAG) as OUTCOME\n",
    "\n",
    "  -- this is a case statement - essentially an \"if, else\" clause\n",
    "  , min(\n",
    "      case\n",
    "        -- if the itemid is 211\n",
    "        when itemid = 211\n",
    "          -- then return the actual value stored in VALUENUM\n",
    "          then valuenum\n",
    "        -- otherwise, return 'null', which is SQL standard for an empty value\n",
    "        else null\n",
    "      -- end the case statement\n",
    "      end\n",
    "    ) as HeartRate_Min\n",
    "\n",
    "    -- note we wrapped the above in \"min()\"\n",
    "    -- this takes the minimum of all values inside, and *ignores* nulls\n",
    "    -- by calling this on our case statement, we are ignoring all values except those with ITEMID = 211\n",
    "    -- since ITEMID 211 are heart rates, we take the minimum of only heart rates\n",
    "\n",
    "  , max(case when itemid = 211 then valuenum else null end) as HeartRate_Max\n",
    "  , min(case when itemid in (615,618) then valuenum else null end) as RespRate_Min\n",
    "  , max(case when itemid in (615,618) then valuenum else null end) as RespRate_Max\n",
    "from icustays ie\n",
    "\n",
    "-- join to the admissions table to get hospital outcome\n",
    "inner join admissions adm\n",
    "  on ie.hadm_id = adm.hadm_id\n",
    "\n",
    "-- join to the chartevents table to get the observations\n",
    "left join ce\n",
    "  -- match the tables on the patient identifier\n",
    "  on ie.icustay_id = ce.icustay_id\n",
    "  -- and require that the observation be made after the patient is admitted to the ICU\n",
    "  and ce.charttime >= ie.intime\n",
    "  -- and *before* their admission time + 1 day, i.e. the observation must be made on their first day in the ICU\n",
    "  and ce.charttime <= ie.intime + interval '1' day\n",
    "group by ie.icustay_id\n",
    "order by ie.icustay_id\n",
    "\"\"\"\n",
    "\n",
    "data = wr.athena.read_sql_query(query,database)\n",
    "data.drop('icustay_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>heartrate_min</th>\n",
       "      <th>heartrate_max</th>\n",
       "      <th>resprate_min</th>\n",
       "      <th>resprate_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome  heartrate_min  heartrate_max  resprate_min  resprate_max\n",
       "0        0            NaN            NaN           NaN           NaN\n",
       "1        0           72.0          122.0          14.0          39.0\n",
       "2        0           62.0           84.0          14.0          27.0\n",
       "3        0           80.0          104.0          13.0          29.0\n",
       "4        0           88.0          106.0          13.0          22.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61532, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should have +60K rows in our dataset represeting patients from the MIMIC-III dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "\n",
    "Here we develop, train and test the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move from a data frame into a numpy array\n",
    "X = data.iloc[:,1:].to_numpy()\n",
    "y = data['outcome'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to numeric types\n",
    "X = X.astype(float)\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in 80%-20% training/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute mean for missing values, since we have only numerical values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(fit_intercept=True, solver='lbfgs')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "We evaluate our model locally, analyzing the test dataset and using AUROC, confusion matrices and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8944503128300967\n",
      "AUROC = 0.6098985793469475\n",
      "\n",
      "Confusion matrix\n",
      "[[10956    20]\n",
      " [ 1279    52]]\n",
      "\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94     10976\n",
      "           1       0.72      0.04      0.07      1331\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     12307\n",
      "   macro avg       0.81      0.52      0.51     12307\n",
      "weighted avg       0.88      0.89      0.85     12307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict class labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# generate class probabilities\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# generate evaluation metrics\n",
    "print('Accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('AUROC = {}'.format(roc_auc_score(y_test, y_prob[:, 1])))\n",
    "\n",
    "print('\\nConfusion matrix')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\nClassification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC for all folds:\n",
      "[0.61605425 0.64243601 0.61885965 0.60049902 0.61505218]\n",
      "Average AUROC across folds:\n",
      "0.6185802217140426\n"
     ]
    }
   ],
   "source": [
    "# evaluate a logistic regression with 5-fold cross-validation\n",
    "estimator = Pipeline([(\"imputer\", SimpleImputer(missing_values=np.nan,\n",
    "                                          strategy=\"mean\")),\n",
    "                      ('scaler', StandardScaler()),\n",
    "                      (\"regression\", LogisticRegressionCV(cv=5,\n",
    "                                                          scoring='roc_auc',\n",
    "                                                          solver='lbfgs'))])\n",
    "\n",
    "scores = cross_val_score(estimator\n",
    "                         , X, y\n",
    "                         , scoring='roc_auc', cv=5)\n",
    "\n",
    "\n",
    "print('AUROC for all folds:')\n",
    "print(scores)\n",
    "print('Average AUROC across folds:')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8944503128300967\n",
      "AUROC = 0.6098985793469475\n"
     ]
    }
   ],
   "source": [
    "# train pipeline\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# predict class labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# generate class probabilities\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# generate evaluation metrics\n",
    "print('Accuracy = {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('AUROC = {}'.format(roc_auc_score(y_test, y_prob[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model.joblib']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test saving and loading model locally\n",
    "import joblib\n",
    "\n",
    "joblib.dump(estimator, os.path.join('./', \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('regression', LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, i...andom_state=None, refit=True, scoring='roc_auc',\n",
       "           solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = joblib.load(os.path.join('./', \"model.joblib\"))\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment\n",
    "We finally deploy in SageMaker, in a managed training and hosting infrastructure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about SageMaker, get out the [docs](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html).\n",
    "\n",
    "Remember to add permissions of SageMakerFullAccess to IAM Role of the notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'Scikit-mimic'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory and write csv\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "np.savetxt('./data/mimic.csv', data, delimiter=',', fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in S3 for training with SageMaker\n",
    "data_dir = 'data'\n",
    "train_input = sagemaker_session.upload_data(data_dir, key_prefix=\"{}/{}\".format(prefix, data_dir) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = 'scikit_learn_mimic.py'\n",
    "\n",
    "# Simple training without hyperparameters\n",
    "# The entry script in a python script based on the code developed above\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see SageMaker spinning up instances for training:\n",
    "\n",
    "![sm-train](./media/sagemaker-training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see SageMaker spinning up instances for hosting the model with an API endpoint:\n",
    "\n",
    "![sm-train](./media/sagemaker-hosting.png)\n",
    "\n",
    "![sm-train](./media/sagemaker-hosting-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint for avoid costs\n",
    "sklearn.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
